# Побудова системи класифікації новин із використанням методів машинного та глибокого навчання

Метою даного проєкту є побудова системи класифікації новин із використанням методів машинного та глибинного навчання,
здатної ефективно розрізняти фейкові та справжні новини на основі їхнього заголовка та основного тексту. У якості
відправної точки реалізовано baseline-модель логістичної регресії з використанням векторизації, що
слугує базовою оцінкою якості.

Подальше вдосконалення здійснено за допомогою нейронних мереж, зокрема двогілкової LSTM-моделі, яка окремо обробляє
заголовок і текст новини, а також CNN-моделі, що дозволяє виділяти локальні шаблони та ключові патерни. Для побудови
векторних представлень використано попередньо натреновані GloVe-ембедінги, які зберігають семантичну структуру мови.

Окрему увагу приділено інтерпретованості моделей. З використанням бібліотеки Captum реалізовано аналіз важливості
токенів на основі методу Integrated Gradients, що дозволяє виявити, які саме частини тексту впливають на рішення моделі.

Під час дослідження було виявлено наявність потенційно "витікаючих" ознак — лексем, які штучно підвищують точність
класифікації, але не несуть реальної узагальнюючої здатності.

Таким чином, проєкт демонструє повний цикл побудови системи виявлення фейкових новин — від очищення тексту та побудови
словника до розробки глибинних архітектур і пояснення їхніх рішень, підкреслюючи важливість як точності, так і
прозорості в задачах соціального значення.

Для зручності рішення розділення на декілька ноутбуків:

- [1. Exploratory Data Analysis](notebook/1_eda.ipynb)
- [2. Baseline Model](notebook/2_baseline_model.ipynb)
- [3. Preprocessing](notebook/3_preprocessing.ipynb)
- [4.1 Modeling with RNN](notebook/4_1_modeling_rnn.ipynb)
- [4.2 Modeling with LSTM](notebook/4_2_modeling_lstm.ipynb)

### Exploratory Data Analysis (EDA)

Більш детально з дослідженням та отриманими висновками можна ознайомитись в [ноутбуці](notebook/1_eda.ipynb).

Під час початкового аналізу даних було здійснено детальний огляд структури, вмісту та стилістичних особливостей фейкових
і реальних новин. Проведено аналіз пропущених значень, типів ознак та збалансованості класів.
Також досліджено структуру заголовків і текстів, а також розподіл токенів. Проведено лексичний і часовий аналіз.

EDA дозволив виявити важливі патерни у структурі, стилі та динаміці новин:

- **Фейкові новини** зазвичай довші, менш стандартизовані, з гучними заголовками та більш емоційним наповненням.
- **Справжні новини** формальніші, компактніші, з нейтральною лексикою.
- Часовий зріз демонструє, що фейковий контент переважав на початку, але згодом **баланс змістився**.

### Baseline Model

Більш детально з дослідженням та отриманими висновками можна ознайомитись в [ноутбуці](notebook/2_baseline_model.ipynb).

На етапі побудови базової моделі було застосовано два підходи до векторизації тексту — CountVectorizer і TF-IDF, які
перетворюють тексти на розріджені вектори, добре придатні для лінійних моделей.

- Для побудови базової моделі було використано **логістичну регресію** з двома способами векторизації: `CountVectorizer`
  та `TF-IDF`.
- Навчання проводилось на об’єднаному полі `full_text` (заголовок + текст), без складної обробки структури новини.
- Проведено аналіз **ключових слів**: модель розпізнає фейки за емоційною лексикою, реальні новини — за
  формальною структурою.
- Проведено дослідження на пошук **артефактних токенів**, які могли б впливати на рішення моделі.
- Для порівняння протестовано **XGBoost**, який показав гірші результати — ймовірно через природу розріджених ознак.

#### Дослідження витоку даних

Після отримання високих метрик на базовій моделі було перевірено можливість витоку даних:

- Перемішування міток показало різке падіння якості, отже модель навчалась на реальних закономірностях.
- Аналіз лексики виявив артефактні токени, що траплялись лише у фейкових (`https`, `getty`, `cdata`) або лише у
  справжніх (`reuters`, `factbox`, `tuesday`) новинах.
- Була реалізована спроба видалення “leaky words” перед векторизацією. Видалення артефактів не покращило якість.

**Висновок:** модель все ж таки використовує справжні патерни, але частково орієнтується на технічні токени, спроби
модифікації такого набору вхідних даних не привели до його покращення.

### Preprocessing for Deep Learning Models

Більш детально з дослідженням та отриманими висновками можна ознайомитись в [ноутбуці](notebook/3_preprocessing.ipynb).

Мета даного етапу - підготувати дані у форматі, зручному для подачі в моделі глибокого навчання,
використовуючи GloVe-ембедінги, паддінг, токенізацію та побудову векторного словника.

Загалом на даному етапі:

- Побудовано словник токенів на основі очищених заголовків і текстів.
- Тексти перетворено в послідовності індексів з паддінгом (`<PAD>`) та обмеженою довжиною:
    - Заголовок: max_len = 30
    - Текст: max_len = 800
- Збережено підготовлені тензори. Завантажено та інтегровано GloVe-ембедінги.

Також створено візуалізації з використанням зменшення розмірностей з PCA, щоб показати як GloVe репрезентує подібність
токенів присутніх у досліджуваних новинах.

### Modeling via Deep Learning

На даному етапі було проведено експерименти з використанням моделей глибокого навчання.

Кожна має дві ключові складові:

- Заголовок — короткий, часто емоційний, використовується для привернення уваги.
- Основний текст — містить деталі, факти, контекст.

Обидва компоненти можуть нести різну стилістичну та інформаційну вагу у визначенні, чи новина є фейковою.

У випадку простих моделей заголовок та текст новини був об'єднаний. На даному етапі злиття двох ознак не відбувається,
оскільки обидва компоненти можуть нести різну стилістичну та інформаційну вагу у визначенні, чи новина є фейковою.

Отже, архітектура наступних моделей створена так, щоб мати можливість дослідити окреме представлення кожної частини
новини.

Таким чином у ході експериментів було протестовано дві архітектури глибинних моделей:

- GRU (RNN) (більш детально в [ноутбуці](notebook/4_1_modeling_rnn.ipynb))
- BiLSTM (більш детально в [ноутбуці](notebook/4_2_modeling_lstm.ipynb))

Кожна з моделей використовувала спільне попереднє векторне представлення тексту. Оцінювання проводилося за основними
метриками якості — F1-мірою та ROC-AUC на валідаційному наборі даних, із застосуванням механізму ранньої
зупинки (EarlyStopping) для запобігання перенавчанню.

### Model explaining

Більш детально з дослідженням та отриманими висновками можна ознайомитись
в [ноутбуці](notebook/5_model_explaining.ipynb).


## Результати
