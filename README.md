# Побудова системи класифікації новин із використанням методів машинного та глибокого навчання

Метою даного проєкту є побудова системи класифікації новин із використанням методів машинного та глибинного навчання,
здатної ефективно розрізняти фейкові та справжні новини на основі їхнього заголовка та основного тексту. У якості
відправної точки реалізовано baseline-модель логістичної регресії з використанням векторизації, що
слугує базовою оцінкою якості.

Подальше вдосконалення здійснено за допомогою нейронних мереж, зокрема двогілкової LSTM-моделі, яка окремо обробляє
заголовок і текст новини, а також CNN-моделі, що дозволяє виділяти локальні шаблони та ключові патерни. Для побудови
векторних представлень використано попередньо натреновані GloVe-ембедінги, які зберігають семантичну структуру мови.

Окрему увагу приділено інтерпретованості моделей. З використанням бібліотеки Captum реалізовано аналіз важливості
токенів на основі методу Integrated Gradients, що дозволяє виявити, які саме частини тексту впливають на рішення моделі.

Під час дослідження було виявлено наявність потенційно "витікаючих" ознак — лексем, які штучно підвищують точність
класифікації, але не несуть реальної узагальнюючої здатності.

Таким чином, проєкт демонструє повний цикл побудови системи виявлення фейкових новин — від очищення тексту та побудови
словника до розробки глибинних архітектур і пояснення їхніх рішень, підкреслюючи важливість як точності, так і
прозорості в задачах соціального значення.

Для зручності рішення розділення на декілька ноутбуків:

- [1. Exploratory Data Analysis](notebook/1_eda.ipynb)
- [2. Baseline Model](notebook/2_baseline_model.ipynb)
- [3. Preprocessing](notebook/3_preprocessing.ipynb)
- [4.1 Modeling with RNN](notebook/4_1_modeling_rnn.ipynb)
- [4.2 Modeling with LSTM](notebook/4_2_modeling_lstm.ipynb)

### Exploratory Data Analysis (EDA)

Більш детально з дослідженням та отриманими висновками можна ознайомитись в [ноутбуці](notebook/1_eda.ipynb).

Під час початкового аналізу даних було здійснено детальний огляд структури, вмісту та стилістичних особливостей фейкових
і реальних новин. Проведено аналіз пропущених значень, типів ознак та збалансованості класів.
Також досліджено структуру заголовків і текстів, а також розподіл токенів. Проведено лексичний і часовий аналіз.

EDA дозволив виявити важливі патерни у структурі, стилі та динаміці новин:

- **Фейкові новини** зазвичай довші, менш стандартизовані, з гучними заголовками та більш емоційним наповненням.
- **Справжні новини** формальніші, компактніші, з нейтральною лексикою.
- Часовий зріз демонструє, що фейковий контент переважав на початку, але згодом **баланс змістився**.

### Baseline Model

Більш детально з дослідженням та отриманими висновками можна ознайомитись в [ноутбуці](notebook/2_baseline_model.ipynb).

На етапі побудови базової моделі було застосовано два підходи до векторизації тексту — CountVectorizer і TF-IDF, які
перетворюють тексти на розріджені вектори, добре придатні для лінійних моделей.

- Для побудови базової моделі було використано **логістичну регресію** з двома способами векторизації: `CountVectorizer`
  та `TF-IDF`.
- Навчання проводилось на об’єднаному полі `full_text` (заголовок + текст), без складної обробки структури новини.
- Проведено аналіз **ключових слів**: модель розпізнає фейки за емоційною лексикою, реальні новини — за
  формальною структурою.
- Проведено дослідження на пошук **артефактних токенів**, які могли б впливати на рішення моделі.
- Для порівняння протестовано **XGBoost**, який показав гірші результати — ймовірно через природу розріджених ознак.

#### Дослідження витоку даних

Після отримання високих метрик на базовій моделі було перевірено можливість витоку даних:

- Перемішування міток показало різке падіння якості, отже модель навчалась на реальних закономірностях.
- Аналіз лексики виявив артефактні токени, що траплялись лише у фейкових (`https`, `getty`, `cdata`) або лише у
  справжніх (`reuters`, `factbox`, `tuesday`) новинах.
- Була реалізована спроба видалення “leaky words” перед векторизацією. Видалення артефактів не покращило якість.

**Висновок:** модель все ж таки використовує справжні патерни, але частково орієнтується на технічні токени, спроби
модифікації такого набору вхідних даних не привели до його покращення.

### Preprocessing for Deep Learning Models

Більш детально з дослідженням та отриманими висновками можна ознайомитись в [ноутбуці](notebook/3_preprocessing.ipynb).

Мета даного етапу - підготувати дані у форматі, зручному для подачі в моделі глибокого навчання,
використовуючи GloVe-ембедінги, паддінг, токенізацію та побудову векторного словника.

Загалом на даному етапі:

- Побудовано словник токенів на основі очищених заголовків і текстів.
- Тексти перетворено в послідовності індексів з паддінгом (`<PAD>`) та обмеженою довжиною:
    - Заголовок: max_len = 30
    - Текст: max_len = 800
- Збережено підготовлені тензори. Завантажено та інтегровано GloVe-ембедінги.

Також створено візуалізації з використанням зменшення розмірностей з PCA, щоб показати як GloVe репрезентує подібність
токенів присутніх у досліджуваних новинах.

### Modeling via Deep Learning

На даному етапі було проведено експерименти з використанням моделей глибокого навчання.

Кожна має дві ключові складові:

- Заголовок — короткий, часто емоційний, використовується для привернення уваги.
- Основний текст — містить деталі, факти, контекст.

Обидва компоненти можуть нести різну стилістичну та інформаційну вагу у визначенні, чи новина є фейковою.

У випадку простих моделей заголовок та текст новини був об'єднаний. На даному етапі злиття двох ознак не відбувається,
оскільки обидва компоненти можуть нести різну стилістичну та інформаційну вагу у визначенні, чи новина є фейковою.

Отже, архітектура наступних моделей створена так, щоб мати можливість дослідити окреме представлення кожної частини
новини.

Таким чином у ході експериментів було протестовано дві архітектури глибинних моделей:

- GRU (RNN) (більш детально в [ноутбуці](notebook/4_1_modeling_rnn.ipynb))
- BiLSTM (більш детально в [ноутбуці](notebook/4_2_modeling_lstm.ipynb))

Кожна з моделей використовувала спільне попереднє векторне представлення тексту. Оцінювання проводилося за основними
метриками якості — F1-мірою та ROC-AUC на валідаційному наборі даних, із застосуванням механізму ранньої
зупинки (EarlyStopping) для запобігання перенавчанню.

### Model explaining

Більш детально з дослідженням та отриманими висновками можна ознайомитись
в [ноутбуці](notebook/5_model_explaining.ipynb).

На цьому етапі було здійснено інтерпретацію глибинної моделі (BiLSTM), з метою проаналізувати, які саме токени найбільше
впливають на її рішення. Для цього застосовано метод Integrated Gradients з бібліотеки Captum.

Аналіз проводився окремо для заголовків та основного тексту новини, оскільки обидва компоненти обробляються незалежно у
моделі.

Заголовки новин: модель приділяє найбільшу увагу словам із яскраво вираженим емоційним чи оціночним забарвленням.
Це свідчить про вміння моделі виявляти маніпулятивні або клікбейтні
формулювання.

Високу вагу мають політичні терміни та шаблони, що передають
терміновість. Модель, імовірно, використовує ці шаблони як маркери, пов’язані з риторикою
фейкових новин.

Під час експериментів було згенеровано новини на основі найбільш важливих токенів — і модель
передбачувано класифікувала їх як фейкові. Це підтверджує здатність моделі "вловлювати" стилістичні шаблони.

Аналіз реальних новин: модель також успішно ідентифікує реальні новини, однак її рішення можуть бути упередженими в
присутності тригерних лексем навіть у достовірних текстах.

## Результати

У ході реалізації проєкту було побудовано повноцінну систему для задачі класифікації фейкових новин, що охоплює повний
життєвий цикл ML-проєкту — від аналізу та підготовки даних до побудови моделей і пояснення їх рішень.

Ретельний EDA дозволив виявити патерни, характерні для фейкового та справжнього контенту, включно з емоційним стилем
викладення, політичною лексикою, довжиною тексту й зміною балансу класів у часі.

На базовому етапі логістична регресія з TF-IDF показала високу якість класифікації, однак виявилась чутливою до
технічних артефактів. Це стало причиною глибшого аналізу можливого витоку даних, що було враховано у наступних етапах.

Подальше покращення було досягнуто завдяки впровадженню глибинного навчання: використано двогілкові архітектури BiLSTM
та CNN, які обробляють заголовок і текст окремо, з використанням GloVe-ембедінгів для перенесення семантичного
контексту.

Аналіз інтерпретованості моделей показав, що вони навчаються стилістичним, емоційним та контекстним ознакам фейкових
новин, однак можуть демонструвати упередженість, якщо такі патерни домінують у навчальних даних.

Загалом, система демонструє високу точність і стабільність навіть у складних прикладах, поєднуючи ефективність із
пояснюваністю. При цьому окрема увага приділяється надійності моделей, уникненню data leakage і можливим упередженням —
критично важливим аспектам для задач суспільного значення.